OPENAI_API_KEY = "your-openai-api-key"
ANTHROPIC_API_KEY = "your-anthropic-api-key"
TELOGICAL_AUTH_TOKEN = "your-telogical-auth-token"
TELOGICAL_GRAPHQL_ENDPOINT = "https://residential-api.telogical.com/graphql"
TELOGICAL_AUTH_TOKEN_2 = "your-telogical-auth-token-2"
TELOGICAL_GRAPHQL_ENDPOINT_2 = "https://llmapi.telogical.com/graphql"
TELOGICAL_LOCALE = "us-en"
ZIP_CODE_CSV_PATH = "geo-data.csv"
DMA_CSV_PATH = "DMAs.csv"
LANGCHAIN_TRACING_V2 = true
LANGCHAIN_ENDPOINT="https://api.smith.langchain.com"
LANGCHAIN_API_KEY="your-langchain-api-key"
LANGSMITH_API_KEY="your-langsmith-api-key"
LANGCHAIN_PROJECT="your-langchain-project"

# Telogical Model Configuration

# AZure for Telogical Model (OpenAI GPT 4.1)
TELOGICAL_API_KEY_GPT = "your-telogical-openai-api-key"
TELOGICAL_MODEL_ENDPOINT_GPT = "https://telogical-pricing-llm.openai.azure.com/"
TELOGICAL_MODEL_DEPLOYMENT_GPT = "gpt-4.1"
TELOGICAL_MODEL_API_VERSION_GPT = "2024-12-01-preview"
OPENAI_API_VERSION = "2024-12-01-preview"

# AZure for Telogical Model (Llama 4 Scout Instruct)
AZURE_OPENAI_API_KEY = "your-azure-llama-4-api-key"
AZURE_OPENAI_ENDPOINT = "https://telogical-llama-4-resource.services.ai.azure.com"
TELOGICAL_MODEL_DEPLOYMENT_LLAMA = "Llama-4-Scout-17B-16E-Instruct"
TELOGICAL_MODEL_API_VERSION_LLAMA = "2024-05-01-preview"

# Gemini API Key
GEMINI_API_KEY = "your-gemini-api-key"
NVIDIA_API_KEY = "your-nvidia-api-key"
NVIDIA_API_SECRET = 


# PostgreSQL connection details for Azure Cosmos DB
DB_HOST= "your-postgres-host"
DB_PORT=5432
DB_NAME=citus
DB_USER=citus
DB_PASSWORD= "your-postgres-password"



# API keys for different providers
USE_AWS_BEDROCK=false

# Use a fake model for testing
USE_FAKE_MODEL=false

# Set a default model
DEFAULT_MODEL=

# If MODEL is set to "openai-compatible", set the following
# This is just a flexible solution. If you need multiple model options, you still need to add it to models.py
COMPATIBLE_MODEL=
COMPATIBLE_API_KEY=
COMPATIBLE_BASE_URL=

# Web server configuration
HOST=0.0.0.0
# PORT=8080
PORT = 8081

# Authentication secret, HTTP bearer token header is required if set
AUTH_SECRET=

# Langsmith configuration
# LANGSMITH_TRACING=true
# LANGSMITH_API_KEY=
# LANGSMITH_PROJECT=default
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# Application mode. If the value is "dev", it will enable uvicorn reload
MODE=

# Database type.
# If the value is "postgres", then it will require Postgresql related environment variables.
# If the value is "sqlite", then you can configure optional file path via SQLITE_DB_PATH
DATABASE_TYPE= postgres

# If DATABASE_TYPE=sqlite (Optional)
SQLITE_DB_PATH=

# If DATABASE_TYPE=postgres
# Docker Compose default values (will work with docker-compose setup)
POSTGRES_USER= citus
POSTGRES_PASSWORD= "your-postgres-password"
POSTGRES_HOST= "your-postgres-host"
POSTGRES_PORT= 5432
POSTGRES_DB= citus


# Add for running Azure OpenAI
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_API_VERSION=2024-10-21
AZURE_OPENAI_DEPLOYMENT_MAP={"gpt-4o": "gpt-4.1", "gpt-4o-mini": "gpt-4.1"}

# Agent URL: used in Streamlit app - if not set, defaults to http://{HOST}:{PORT}
# AGENT_URL=http://0.0.0.0:8080
